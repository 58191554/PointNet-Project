{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEyQ3RTlsiK3kpieH3L5o7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/58191554/PointNet-Project/blob/main/ModelAssert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DS7B7VwzLtL3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "seed = 42"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Tnet(nn.Module):\n",
        "    \"\"\"\n",
        "    T-Net is a type of spatial transformer network (STN) that learns a kxk transformation matrix\n",
        "    for a given point cloud. The matrix is then used to transform the point cloud to a canonical\n",
        "    pose. It consists of two parts: a convolutional network and a fully connected network.\n",
        "    The convolutional network maps the input point cloud to a feature space and the fully connected\n",
        "    network learns the transformation matrix from the feature space.\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_sizes_conv=[64, 128, 1024], hidden_sizes_fc=[512, 256], k=3):\n",
        "        super().__init__()\n",
        "        self.k=k\n",
        "        self.hidden_sizes_conv=hidden_sizes_conv\n",
        "        self.hidden_sizes_fc=hidden_sizes_fc\n",
        "        \n",
        "        self.conv = self._build_conv()\n",
        "        self.fc = self._build_fc()\n",
        "  \n",
        "    def _build_conv(self):\n",
        "        ########################################################################\n",
        "        # TODO: Builds the convolutional network that maps the input point cloud \n",
        "        # to a feature space. The hidden dimension is hidden_sizes_conv\n",
        "        #  \n",
        "        # Hint: consisting of a series of convolutional layers with batch \n",
        "        # normalization and ReLU activation.\n",
        "        #   The convolution layers is in following structure:\n",
        "        #   [conv1d]-> [Batch Norm Layer] -> [ReLU]-> [conv1d]-> ...\n",
        "        ########################################################################\n",
        "        layers = []\n",
        "        prev_size = self.k\n",
        "        for layer_id, size in enumerate(self.hidden_sizes_conv):\n",
        "            bn = nn.BatchNorm1d(size)\n",
        "            conv = nn.Conv1d(prev_size, size,1)\n",
        "            layers.append(conv)\n",
        "            layers.append(bn)\n",
        "            layers.append(nn.ReLU())\n",
        "            prev_size = size\n",
        "        ########################################################################\n",
        "        return nn.Sequential(*layers)\n",
        "  \n",
        "    def _build_fc(self):\n",
        "        ########################################################################\n",
        "        # TODO:  the fully connected network that takes the feature space and \n",
        "        # learns the transformation matrix. \n",
        "        #   The hidden_layers according to hidden_sizes_fc\n",
        "        # \n",
        "        # Hint: the fully connected structur is as follows:\n",
        "        #   [Fully Connected Layer]-> [Batch Norm Layer] -> [ReLU]-> [Fully Connected Layer]-> ...\n",
        "        ########################################################################\n",
        "        layers = []\n",
        "        prev_size = self.hidden_sizes_conv[-1]\n",
        "        for layer_id, size in enumerate(self.hidden_sizes_fc):\n",
        "            bn = nn.BatchNorm1d(size)\n",
        "            fc = nn.Linear(prev_size, size)\n",
        "            layers.append(fc)\n",
        "            layers.append(bn)\n",
        "            layers.append(nn.ReLU())\n",
        "            prev_size = size\n",
        "        layers.append(nn.Linear(self.hidden_sizes_fc[-1],self.k**2))\n",
        "        ########################################################################\n",
        "        return nn.Sequential(*layers)\n",
        "      \n",
        "\n",
        "    def forward(self, input):\n",
        "        ########################################################################\n",
        "        # TODO: Performs the forward pass of the T-Net. \n",
        "        # It first applies the convolutional network to the input point cloud \n",
        "        # to obtain a feature space. \n",
        "        # Then, it applies the fully connected network to the feature space to \n",
        "        # obtain the kxk transformation matrix. Finally, it applies the\n",
        "        # transformation matrix to the input point cloud to transform it to a \n",
        "        # canonical pose.\n",
        "        # \n",
        "        # Hint: the forward structure is as follows:\n",
        "        # [ConvLayers]->[MaxPooling]->[Flatten]->[Fully Connected Layers]->[theta_Matrix + identity]\n",
        "        #   The identity require gradient\n",
        "        ########################################################################\n",
        "        # input.shape (bs,n,3)\n",
        "        bs = input.size(0)\n",
        "        \n",
        "        xb = self.conv(input)   \n",
        "        pool = nn.MaxPool1d(xb.size(-1))(xb)\n",
        "        flat = nn.Flatten(1)(pool)\n",
        "        xb = self.fc(flat)\n",
        "      \n",
        "        init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n",
        "        if xb.is_cuda:\n",
        "          init=init.cuda()\n",
        "        matrix = xb.view(-1,self.k,self.k) + init        \n",
        "        return matrix"
      ],
      "metadata": {
        "id": "BbkCjFwWLyyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "test_t_net = Tnet()\n",
        "\n",
        "if count_parameters(test_t_net)!=803081:\n",
        "    print(\"Error\")\n",
        "    print(\"test_t_net parameters number = \", count_parameters(test_t_net))\n",
        "\n",
        "assert count_parameters(test_t_net)==803081\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "x1 = torch.randn(3, 3, 5)\n",
        "\n",
        "\n",
        "y1 = torch.tensor([[[ 2.4067,  0.2867,  0.0376],\n",
        "         [ 0.7862,  0.6480,  0.5361],\n",
        "         [ 0.0954, -0.2747,  1.0449]],\n",
        "\n",
        "        [[ 1.4776, -0.4632, -0.0986],\n",
        "         [ 1.2216,  0.7514, -0.6017],\n",
        "         [-0.4946,  0.4135,  1.2490]],\n",
        "\n",
        "        [[ 1.3951,  0.7168, -0.2013],\n",
        "         [-0.3767,  1.9410, -0.8459],\n",
        "         [ 0.5701, -0.0262,  1.0335]]])\n",
        "pred_y1 = test_t_net(x1)\n",
        "print(pred_y1)\n",
        "assert torch.allclose(y1, pred_y1, rtol=1e-03, atol=1e-03),  \"different y_pred and y\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "esqdzu8iL6mR",
        "outputId": "9d473b33-37c0-4d4e-eb9c-7d3142a03d84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.8501,  0.1849, -0.2045],\n",
            "         [-0.0936,  0.9165,  0.4215],\n",
            "         [ 0.0244,  0.0145,  0.7206]],\n",
            "\n",
            "        [[ 1.2012,  0.2271, -0.0122],\n",
            "         [-0.1934,  0.2646,  0.3887],\n",
            "         [ 0.1313, -0.1262,  0.4967]],\n",
            "\n",
            "        [[ 0.5446,  0.3135, -0.0992],\n",
            "         [-0.4373,  1.8131,  0.7287],\n",
            "         [-0.0117,  0.1228,  0.6404]]], grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-4b7af46f3cf4>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mpred_y1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_t_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_y1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_y1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-03\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-03\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"different y_pred and y\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: different y_pred and y"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Transform(nn.Module):\n",
        "    def __init__(self, input_size=3, feature_size=64, sharedMLP1_layers=[64, 64], sharedMLP2_layers=[64, 128, 1024], batch_norm = True):\n",
        "        \"\"\"\n",
        "        Transform class is all the pipeline to get a global feature\n",
        "                 _____________________                                     _______________                 ___________________       _______________\n",
        "                |                     |                                   |               |                |                 |     |               |                    \n",
        "        x -->   |   input transform   | --> y (canonical point cloud) --> |  shared MLP   | --> feature -->|feature transform| --> |  shared MLP   | --> max pooling --> z\n",
        "                |_____________________|                                   |_______________|                |_________________|     |  _____________|\n",
        "        The transform class is a neural networknet architecture that go throught 2 pairs of spactial transform net and shared MLP.\n",
        "        The STN is the T-Net that implement above, and the shared-MLP can be regarded as a one-dimensional convolutional layer.\n",
        "\n",
        "        the input x as a point cloud data of (nx3) shape first compute the 3x3 transform matrix and multiplied with the transform matrix to get a (nx3) transformed point cloud.\n",
        "\n",
        "        the last_activate bool is True when you want to add the last layer with activation function.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.batch_norm = True\n",
        "        \n",
        "        self.input_transform = Tnet(k=3)\n",
        "        self.feature_transform = Tnet(k=64)\n",
        "\n",
        "        self.sharedMLP1 = self._build_sharedMLP(input_size, sharedMLP1_layers, last_activate=True)\n",
        "        self.sharedMLP2 = self._build_sharedMLP(feature_size, sharedMLP2_layers, last_activate=False)\n",
        "\n",
        "    def _build_sharedMLP(self, input_dim, sharedMLP_layers, last_activate = True):\n",
        "        ########################################################################\n",
        "        # TODO: Build the shared MLP layers \n",
        "        # Hint: \n",
        "        #   The structure is [Conv1d]->[Batch Norm]->[ReLU]\n",
        "        ########################################################################\n",
        "        layers = []\n",
        "        prev_size = input_dim\n",
        "        for layer_id, size in enumerate(sharedMLP_layers):\n",
        "            layers.append(nn.Conv1d(prev_size, size, 1))\n",
        "\n",
        "            if self.batch_norm:\n",
        "                layers.append(nn.BatchNorm1d(size))\n",
        "\n",
        "            if (layer_id < len(sharedMLP_layers)-1) or last_activate:\n",
        "                layers.append(nn.ReLU())\n",
        "\n",
        "            prev_size = size\n",
        "        return nn.Sequential(*layers)\n",
        "       \n",
        "    def forward(self, input):     #input:[batch_size, 3, 1024] output:[batch_size, 1024]\n",
        "    \n",
        "        ########################################################################\n",
        "        # TODO: Implement the code to multiply the transform matrix and the point\n",
        "        # cloud. The transformed x should be the same shape of x \n",
        "        # \n",
        "        # Hint: \n",
        "        # 1. Get the transform matrix by the T-Net\n",
        "        # 2. Batch matrix multiply the input x and transform matrix\n",
        "        # 3. Input the data into the Shared MLP\n",
        "        # 4. Batch matrix multiply the feature and the feature_transform matrix\n",
        "        # 5. Input the output into the Shared MLP with feature dimension\n",
        "        # 6. Maxpooling along the feature dimension\n",
        "        # 7. output the output data, points transform matrix, and the feature\n",
        "        #       transform matrix\n",
        "        ########################################################################\n",
        "        matrix3x3 = self.input_transform(input)     #[batch_size, 3, 3]\n",
        "        # batch matrix multiplication\n",
        "        xb = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)     #[batch_size, 3, 1024]\n",
        "        xb = self.sharedMLP1(xb)\n",
        "\n",
        "        matrix64x64 = self.feature_transform(xb)     #[batch_size, 64, 64]\n",
        "        xb = torch.bmm(torch.transpose(xb,1,2), matrix64x64).transpose(1,2)     #[batch_size, 64, 1024]\n",
        "        xb = self.sharedMLP2(xb)\n",
        "\n",
        "        xb = nn.MaxPool1d(xb.size(-1))(xb)     #[batch_size, 1024, 1]\n",
        "        output = nn.Flatten(1)(xb)     #[batch_size, 1024]\n",
        "        ########################################################################\n",
        "        return output, matrix3x3, matrix64x64"
      ],
      "metadata": {
        "id": "HkMoW3AySa4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_transfrom_net = Transform()\n",
        "\n",
        "test_tranform_net_param_num = count_parameters(test_transfrom_net)\n",
        "if test_tranform_net_param_num!=2812105:\n",
        "    print(\"Error\")\n",
        "    print(\"test_transfrom_net parameters number = \", count_parameters(test_transfrom_net))\n",
        "    print(\"Difference = \", torch.absolute(test_tranform_net_param_num!=2812105))\n",
        "\n",
        "assert count_parameters(test_transfrom_net)==2812105\n",
        "\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "x2 = torch.randn(2, 3, 5)\n",
        "pred_y2, pred_mat1, pred_mat2 = test_transfrom_net(x2)\n",
        "\n",
        "mat1 = torch.tensor([[[ 1.4163,  0.5276,  0.1501],\n",
        "         [ 0.5164,  1.1149, -0.3152],\n",
        "         [-0.0963,  0.0254,  0.8117]],\n",
        "\n",
        "        [[ 1.9937, -0.0146, -0.6189],\n",
        "         [ 0.5562,  1.2374, -0.4386],\n",
        "         [ 0.0655,  0.2559,  1.5200]]])\n",
        "\n",
        "if not torch.allclose(mat1, pred_mat1, rtol=1e-03, atol=1e-03):\n",
        "    print(\"Error\")\n",
        "    print(\"The answer mat1 is \\n\", mat1)\n",
        "    print(\"The pred_mat1 is \\n\", pred_mat1)\n",
        "    print(\"Difference = \", torch.norm(pred_mat1- mat1))\n",
        "assert torch.allclose(mat1, pred_mat1, rtol=1e-03, atol=1e-03),  \"different pred_mat1 and mat1\""
      ],
      "metadata": {
        "id": "nr2gIhOOSc37"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}